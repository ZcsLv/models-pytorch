{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.Pipeline\n",
    "# data.Example\n",
    "# data.Iterator.splits\n",
    "# data.field\n",
    "# data.dataSet\n",
    "# data.vocab.stio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 Field对象：预处理某个字段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.legacy import data\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step1:构建Field对象\n",
    "tokenize=lambda x:x.split()\n",
    "# fix_length指定了每条文本的长度，截断补长\n",
    "TEXT = data.Field(sequential=True, tokenize=tokenize, lower=True, fix_length=200)\n",
    "LABEL=data.Field(sequential=False,use_vocab=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step1-1 :读取数据\n",
    "train_data = pd.read_csv('../data/train_one_label.csv')\n",
    "valid_data = pd.read_csv('../data/valid_one_label.csv')\n",
    "test_data = pd.read_csv(\"../data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step2:构建Examples对象\n",
    "\"\"\"\n",
    "torchtext预置的Dataset类的API如下，我们必须至少传入\n",
    "examples和fields这两个参数。examples为由torchtext中的Example对象构造的列表，Example为对数据集中一条数据的抽象。fields可简单理解为每一列数据和Field对象的绑定关系，在下面的代码中将分别用train_examples和test_examples来构建训练集和测试集的examples对象，train_fields和test_fields数据集的fields对象\n",
    "\"\"\"\n",
    "# get_dataset构造并返回Dataset所需的examples和fields\n",
    "def get_dataset(csv_data, text_field, label_field, test=False):\n",
    "\t# id数据对训练在训练过程中没用，使用None指定其对应的field\n",
    "    # comment_text Fileld,toxic为的 name\n",
    "    #  comment_text需要对应到表头的属性值吗，还是随便取一个就好？\n",
    "    fields = [(\"id\", None), # we won't be needing the id, so we pass in None as the field\n",
    "                 (\"comment_text\", text_field), (\"toxic\", label_field)]       \n",
    "    examples = []\n",
    "    if test:\n",
    "        # 如果为测试集，则不加载label\n",
    "        for text in tqdm(csv_data['comment_text']):\n",
    "            examples.append(data.Example.fromlist([None, text, None], fields))\n",
    "    else:\n",
    "        for text, label in tqdm(zip(csv_data['comment_text'], csv_data['toxic'])):\n",
    "            examples.append(data.Example.fromlist([None, text, label], fields))\n",
    "    return examples, fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3:得到构建Dataset所需的examples和fields\n",
    "train_examples, train_fields = get_dataset(train_data, TEXT, LABEL)\n",
    "valid_examples, valid_fields = get_dataset(valid_data, TEXT, LABEL)\n",
    "test_examples, test_fields = get_dataset(test_data, TEXT, None, test=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step4:构建Dataset数据集:class torchtext.data.Dataset(examples, fields, filter_pred=None)\n",
    "train = data.Dataset(train_examples, train_fields)\n",
    "valid = data.Dataset(train_examples, train_fields)\n",
    "test = data.Dataset(train_examples, train_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train)\n",
    "print(len(train))\n",
    "vocab=TEXT.vocab\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step5 ：构建迭代器\n",
    "train_iter, val_iter, test_iter = data.Iterator.splits(\n",
    "        (train, valid, test), sort_key=lambda x: len(x.comment_text_2),\n",
    "        batch_sizes=(10, 10, 10), device=-1)\n",
    "batch = next(iter(train_iter))\n",
    "print(\"batch text: \", batch.comment_text) # 对应 Fileld 的 name\n",
    "print(\"batch label: \", batch.toxic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "def convert_list2dict(convert_list):\n",
    "    list_dict = OrderedDict()\n",
    "    for index, word in enumerate(convert_list):\n",
    "        list_dict[word] = index\n",
    "    return list_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm,torch\n",
    "# 词汇表的词典: token->index\n",
    "text_field_words_dict=TEXT.vocab.itos\n",
    "#这样不是读的所有的词的数量？\n",
    "word_count = len(text_field_words_dict)\n",
    "print(word_count)\n",
    "path=\"../word2vec/glove.sentiment.conj.pretrained.txt\"\n",
    "embedding_dim=300\n",
    "embeddings = np.zeros((int(word_count), int(embedding_dim)))\n",
    "def get_pretained_embedding(path,text_field_words_dict):\n",
    "    #如果没有词汇表，自建一个词汇表\n",
    "    inword_list={}\n",
    "    if not isinstance(text_field_words_dict, dict):\n",
    "        text_field_words_dict = convert_list2dict(text_field_words_dict)\n",
    "    with open(path,encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "        lines = tqdm.tqdm(lines)\n",
    "        for line in lines:\n",
    "            line = line.strip().split(\" \")\n",
    "            index = text_field_words_dict.get(line[0])  # digit or None\n",
    "            vector = np.array([i for i in line[1:]], dtype='float32')\n",
    "            embeddings[index] = vector\n",
    "            inword_list[index] = 1\n",
    "    f.close()\n",
    "    OOVWords = word_count - len(inword_list)\n",
    "    print(\"All Words = {}, InWords = {}, OOVWords = {}\".format(word_count, len(inword_list), OOVWords, oov_radio))\n",
    "    return torch.from_numpy(embeddings).float()\n",
    "get_pretained_embedding(path,text_field_words_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = len(text_field_words_dict)\n",
    "print('The number of wordsDict is {} \\nThe dim of pretrained embedding is {}\\n'.format(str(word_count),\n",
    "                                                                                           str(embedding_dim)))\n",
    "embeddings = np.zeros((int(word_count), int(embedding_dim)))\n",
    "\n",
    "inword_list = {}\n",
    "with open(path, encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    lines = tqdm.tqdm(lines)\n",
    "    for line in lines:\n",
    "        lines.set_description(\"Processing\")\n",
    "        #只剩数字\n",
    "        values = line.strip().split(\" \")\n",
    "        if len(values) == 1 or len(values) == 2:\n",
    "            continue\n",
    "        # value[0]是token 词典可以将token转为index \n",
    "        index = text_field_words_dict.get(values[0])  # digit or None\n",
    "        if index:\n",
    "            vector = np.array([float(i) for i in values[1:]], dtype='float32')\n",
    "            embeddings[index] = vector\n",
    "            inword_list[index] = 1\n",
    "    f.close()\n",
    "print(\"oov words initial by avg embedding, maybe take a while......\")\n",
    "sum_col = np.sum(embeddings, axis=0) / len(inword_list)     # avg\n",
    "for i in range(len(text_field_words_dict)):\n",
    "    if i not in inword_list and i != padID:\n",
    "        embeddings[i] = sum_col\n",
    "\n",
    "OOVWords = word_count - len(inword_list)\n",
    "oov_radio = np.round(OOVWords / word_count, 6)\n",
    "print(\"All Words = {}, InWords = {}, OOVWords = {}, OOV Radio={}\".format(\n",
    "word_count, len(inword_list), OOVWords, oov_radio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 8: 使用 Pytorch 的 Embedding Layer 来解决 embedding lookup 问题。\n",
    "embed = Embedding(len(vocab), emb_dim)\n",
    "embed.weight.data.copy_(vocab.vectors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('models')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b109b4c8678325b4a501b51adb3048a45c353f35475e14cb1c1d6c8714fba358"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
