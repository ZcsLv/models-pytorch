{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参考：https://www.jianshu.com/p/45a26d278473\n",
    "# 参考(point)：https://blog.csdn.net/sunny_xsc1994/article/details/82969867\n",
    "# \n",
    "class CNN1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN1,self).__init__()\n",
    "        words_dim=30\n",
    "        n_filters=10\n",
    "        n_classes=3\n",
    "        n_words=100\n",
    "        ks=2\n",
    "        # 卷积 激活  池化  线性  dropout和batchnorm未加\n",
    "        #x的输入形式：(batches,sequence_words,words_dim)\n",
    "        \"\"\"net的初始化：#class torch.nn.Conv1d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True)\n",
    "            #in_channels:  输入信号的通道，其实就相当于词向量的维度\n",
    "            #out_channels：卷积产生的通道，相当于有多个卷积核，也就是filters的个数\n",
    "            #kernel_size(int or tuple): 卷积核的尺寸，卷积核的大小为(k,)，第二个维度是由in_channels来决定的，所以实际上卷积大小为kernel_size*in_channels\n",
    "            #stride=1：\n",
    "        \"\"\"\n",
    "        self.conv1d=nn.Conv1d(in_channels=words_dim,out_channels=n_filters,kernel_size=ks,stride=1)\n",
    "        self.relu=nn.ReLU()\n",
    "        #参数如何设置？参考：https://blog.csdn.net/sunny_xsc1994/article/details/82969867\n",
    "        self.maxpool=nn.MaxPool1d(kernel_size=n_words-ks+1,stride=1)\n",
    "        #全连接\n",
    "        self.linear=nn.Linear(in_features=n_filters*1,out_features=n_classes)\n",
    "        # self.seq=nn.Sequential(self.conv1d,self.relu,self.maxpool,self.linear)\n",
    "    def forward(self,x):\n",
    "        x=x.permute(0,2,1)\n",
    "        print(x.shape)\n",
    "        x=self.conv1d(x)    # (batches,n_filters,n_words-ks/strides+1)  在卷积的过程中，词向量维度已经消掉了\n",
    "        print(x.shape)\n",
    "        x=self.relu(x)      # (batches,n_filters,n_words-ks/strides+1)\n",
    "        x=self.maxpool(x)   # (batches,n_filters,1)\n",
    "        # 把x做一下cat,也就是把max之后的结果进行concat:(batches,n_filters,1)-->(batches,n_filters*1)\n",
    "        x=x.view(x[0],x[1])\n",
    "        print(x.shape)\n",
    "        x=self.linear(x)    # (batches,n_filters)\n",
    "        print(x.shape)\n",
    "\n",
    "        # x=self.seq(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 文本分类任务中，conv1d的使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 30, 100])\n",
      "torch.Size([5, 10, 99])\n",
      "torch.Size([5, 10, 99])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "view() received an invalid combination of arguments - got (Tensor, Tensor), but expected one of:\n * (tuple of ints size)\n * (torch.dtype dtype)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-c4afd9851b6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbatches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msequence_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwords_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnet1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/models/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-dab0796b4273>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# 把x做一下cat,也就是把max之后的结果进行concat:(batches,n_filters,1)-->(batches,n_filters*1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# (batches,n_filters)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: view() received an invalid combination of arguments - got (Tensor, Tensor), but expected one of:\n * (tuple of ints size)\n * (torch.dtype dtype)\n"
     ]
    }
   ],
   "source": [
    "net1=CNN1()\n",
    "sequence_words=100\n",
    "words_dim=30\n",
    "batches=5\n",
    "input=torch.randn(batches,sequence_words,words_dim)\n",
    "output=net1(input)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.3124],\n",
       "         [-0.5951],\n",
       "         [-0.6303]],\n",
       "\n",
       "        [[ 0.3625],\n",
       "         [-0.1106],\n",
       "         [ 0.4437]],\n",
       "\n",
       "        [[ 0.3031],\n",
       "         [ 0.0203],\n",
       "         [-0.3420]],\n",
       "\n",
       "        [[-0.7803],\n",
       "         [-0.5510],\n",
       "         [ 0.0806]],\n",
       "\n",
       "        [[ 0.6195],\n",
       "         [ 0.6247],\n",
       "         [ 0.8256]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input=torch.randn(5,3,1)\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3124, -0.5951, -0.6303],\n",
       "        [ 0.3625, -0.1106,  0.4437],\n",
       "        [ 0.3031,  0.0203, -0.3420],\n",
       "        [-0.7803, -0.5510,  0.0806],\n",
       "        [ 0.6195,  0.6247,  0.8256]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.view(5,3*1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('models')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b109b4c8678325b4a501b51adb3048a45c353f35475e14cb1c1d6c8714fba358"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
